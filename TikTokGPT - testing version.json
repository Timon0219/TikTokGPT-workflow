{"description": "This flow will get the data URL (csv) and ingest it, build a streamlied RAG pipeline", "icon_bg_color": null, "updated_at": "2024-09-20T16:10:42+00:00", "webhook": false, "id": "7c479603-ba28-4439-98f3-08f94b566430", "name": "TikTokGPT - testing version", "icon": null, "is_component": false, "endpoint_name": null, "data": {"nodes": [{"data": {"description": "Create a prompt template with dynamic variables.", "display_name": "Prompt", "id": "Prompt-bSbBG", "node": {"base_classes": ["Message"], "beta": false, "conditional_paths": [], "custom_fields": {"template": ["Document", "Question"]}, "description": "Create a prompt template with dynamic variables.", "display_name": "Prompt", "documentation": "", "edited": false, "field_order": ["template"], "frozen": false, "icon": "prompts", "output_types": [], "outputs": [{"cache": true, "display_name": "Prompt Message", "method": "build_prompt", "name": "prompt", "selected": "Message", "types": ["Message"], "value": "__UNDEFINED__"}], "pinned": false, "template": {"Document": {"advanced": false, "display_name": "Document", "dynamic": false, "field_type": "str", "fileTypes": [], "file_path": "", "info": "", "input_types": ["Message", "Text"], "list": false, "load_from_db": false, "multiline": true, "name": "Document", "password": false, "placeholder": "", "required": false, "show": true, "title_case": false, "type": "str", "value": ""}, "Question": {"advanced": false, "display_name": "Question", "dynamic": false, "field_type": "str", "fileTypes": [], "file_path": "", "info": "", "input_types": ["Message", "Text"], "list": false, "load_from_db": false, "multiline": true, "name": "Question", "password": false, "placeholder": "", "required": false, "show": true, "title_case": false, "type": "str", "value": ""}, "_type": "Component", "code": {"advanced": true, "dynamic": true, "fileTypes": [], "file_path": "", "info": "", "list": false, "load_from_db": false, "multiline": true, "name": "code", "password": false, "placeholder": "", "required": true, "show": true, "title_case": false, "type": "code", "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"}, "template": {"advanced": false, "display_name": "Template", "dynamic": false, "info": "", "list": false, "load_from_db": false, "name": "template", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "type": "prompt", "value": "Answer user's questions based on the document below:\n\n---\n\n{Document}\n\n---\n\nQuestion:\n{Question}\n\nAnswer:\n"}}, "lf_version": "1.0.18"}, "type": "Prompt"}, "dragging": false, "height": 502, "id": "Prompt-bSbBG", "position": {"x": 637.3518652087848, "y": 47.191730368560215}, "positionAbsolute": {"x": 637.3518652087848, "y": 47.191730368560215}, "selected": false, "type": "genericNode", "width": 384}, {"data": {"description": "Get chat inputs from the Playground.", "display_name": "Chat Input", "id": "ChatInput-DSs0U", "node": {"base_classes": ["Message"], "beta": false, "conditional_paths": [], "custom_fields": {}, "description": "Get chat inputs from the Playground.", "display_name": "Chat Input", "documentation": "", "edited": false, "field_order": ["input_value", "store_message", "sender", "sender_name", "session_id", "files"], "frozen": false, "icon": "ChatInput", "output_types": [], "outputs": [{"cache": true, "display_name": "Message", "method": "message_response", "name": "message", "selected": "Message", "types": ["Message"], "value": "__UNDEFINED__"}], "pinned": false, "template": {"_type": "Component", "code": {"advanced": true, "dynamic": true, "fileTypes": [], "file_path": "", "info": "", "list": false, "load_from_db": false, "multiline": true, "name": "code", "password": false, "placeholder": "", "required": true, "show": true, "title_case": false, "type": "code", "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"}, "files": {"advanced": true, "display_name": "Files", "dynamic": false, "fileTypes": ["txt", "md", "mdx", "csv", "json", "yaml", "yml", "xml", "html", "htm", "pdf", "docx", "py", "sh", "sql", "js", "ts", "tsx", "jpg", "jpeg", "png", "bmp", "image"], "file_path": "", "info": "Files to be sent with the message.", "list": true, "name": "files", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_metadata": true, "type": "file", "value": ""}, "input_value": {"advanced": false, "display_name": "Text", "dynamic": false, "info": "Message to be passed as input.", "input_types": ["Message"], "list": false, "load_from_db": false, "multiline": true, "name": "input_value", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": "Hello"}, "sender": {"advanced": true, "display_name": "Sender Type", "dynamic": false, "info": "Type of sender.", "name": "sender", "options": ["Machine", "User"], "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_metadata": true, "type": "str", "value": "User"}, "sender_name": {"advanced": true, "display_name": "Sender Name", "dynamic": false, "info": "Name of the sender.", "input_types": ["Message"], "list": false, "load_from_db": false, "name": "sender_name", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": "User"}, "session_id": {"advanced": true, "display_name": "Session ID", "dynamic": false, "info": "The session ID of the chat. If empty, the current session ID parameter will be used.", "input_types": ["Message"], "list": false, "load_from_db": false, "name": "session_id", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": ""}, "should_store_message": {"_input_type": "BoolInput", "advanced": true, "display_name": "Store Messages", "dynamic": false, "info": "Store the message in the history.", "list": false, "name": "should_store_message", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_metadata": true, "type": "bool", "value": true}}, "lf_version": "1.0.18"}, "type": "ChatInput"}, "dragging": false, "height": 302, "id": "ChatInput-DSs0U", "position": {"x": 50.08709924122684, "y": 320.88186720121615}, "positionAbsolute": {"x": 50.08709924122684, "y": 320.88186720121615}, "selected": false, "type": "genericNode", "width": 384}, {"data": {"description": "Display a chat message in the Playground.", "display_name": "Chat Output", "id": "ChatOutput-qVzbh", "node": {"base_classes": ["Message"], "beta": false, "conditional_paths": [], "custom_fields": {}, "description": "Display a chat message in the Playground.", "display_name": "Chat Output", "documentation": "", "edited": false, "field_order": ["input_value", "store_message", "sender", "sender_name", "session_id", "data_template"], "frozen": false, "icon": "ChatOutput", "output_types": [], "outputs": [{"cache": true, "display_name": "Message", "method": "message_response", "name": "message", "selected": "Message", "types": ["Message"], "value": "__UNDEFINED__"}], "pinned": false, "template": {"_type": "Component", "code": {"advanced": true, "dynamic": true, "fileTypes": [], "file_path": "", "info": "", "list": false, "load_from_db": false, "multiline": true, "name": "code", "password": false, "placeholder": "", "required": true, "show": true, "title_case": false, "type": "code", "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"}, "data_template": {"advanced": true, "display_name": "Data Template", "dynamic": false, "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.", "input_types": ["Message"], "list": false, "load_from_db": false, "name": "data_template", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": "{text}"}, "input_value": {"advanced": false, "display_name": "Text", "dynamic": false, "info": "Message to be passed as output.", "input_types": ["Message"], "list": false, "load_from_db": false, "name": "input_value", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": ""}, "sender": {"advanced": true, "display_name": "Sender Type", "dynamic": false, "info": "Type of sender.", "name": "sender", "options": ["Machine", "User"], "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_metadata": true, "type": "str", "value": "Machine"}, "sender_name": {"advanced": true, "display_name": "Sender Name", "dynamic": false, "info": "Name of the sender.", "input_types": ["Message"], "list": false, "load_from_db": false, "name": "sender_name", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": "AI"}, "session_id": {"advanced": true, "display_name": "Session ID", "dynamic": false, "info": "The session ID of the chat. If empty, the current session ID parameter will be used.", "input_types": ["Message"], "list": false, "load_from_db": false, "name": "session_id", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": ""}, "should_store_message": {"_input_type": "BoolInput", "advanced": true, "display_name": "Store Messages", "dynamic": false, "info": "Store the message in the history.", "list": false, "name": "should_store_message", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_metadata": true, "type": "bool", "value": true}}, "lf_version": "1.0.16.post6"}, "type": "ChatOutput"}, "dragging": false, "height": 302, "id": "ChatOutput-qVzbh", "position": {"x": 1831.1359796346408, "y": 139.5174517327903}, "positionAbsolute": {"x": 1831.1359796346408, "y": 139.5174517327903}, "selected": false, "type": "genericNode", "width": 384}, {"data": {"description": "Convert Data into plain text following a specified template.", "display_name": "Parse Data", "id": "ParseData-Opo2C", "node": {"base_classes": ["Message"], "beta": false, "conditional_paths": [], "custom_fields": {}, "description": "Convert Data into plain text following a specified template.", "display_name": "Parse Data", "documentation": "", "edited": false, "field_order": ["data", "template", "sep"], "frozen": false, "icon": "braces", "output_types": [], "outputs": [{"cache": true, "display_name": "Text", "method": "parse_data", "name": "text", "selected": "Message", "types": ["Message"], "value": "__UNDEFINED__"}], "pinned": false, "template": {"_type": "Component", "code": {"advanced": true, "dynamic": true, "fileTypes": [], "file_path": "", "info": "", "list": false, "load_from_db": false, "multiline": true, "name": "code", "password": false, "placeholder": "", "required": true, "show": true, "title_case": false, "type": "code", "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n"}, "data": {"advanced": false, "display_name": "Data", "dynamic": false, "info": "The data to convert to text.", "input_types": ["Data"], "list": false, "name": "data", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "other", "value": ""}, "sep": {"advanced": true, "display_name": "Separator", "dynamic": false, "info": "", "list": false, "load_from_db": false, "name": "sep", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_metadata": true, "type": "str", "value": "\n"}, "template": {"advanced": false, "display_name": "Template", "dynamic": false, "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.", "input_types": ["Message"], "list": false, "load_from_db": false, "multiline": true, "name": "template", "placeholder": "", "required": false, "show": true, "title_case": false, "trace_as_input": true, "trace_as_metadata": true, "type": "str", "value": "{text}"}}, "lf_version": "1.0.18"}, "type": "ParseData"}, "dragging": false, "height": 378, "id": "ParseData-Opo2C", "position": {"x": 18.015454617798582, "y": -200.5061134794906}, "positionAbsolute": {"x": 18.015454617798582, "y": -200.5061134794906}, "selected": true, "type": "genericNode", "width": 384}, {"id": "GoogleGenerativeAIModel-Se45g", "type": "genericNode", "position": {"x": 1218.5478040783785, "y": 112.3811252782433}, "data": {"type": "GoogleGenerativeAIModel", "node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=[\"gemini-1.5-pro\", \"gemini-1.5-flash\", \"gemini-1.0-pro\", \"gemini-1.0-pro-vision\"],\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError:\n            raise ImportError(\"The 'langchain_google_genai' package is required to use the Google Generative AI model.\")\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatGoogleGenerativeAI(  # type: ignore\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key),\n        )\n\n        return output  # type: ignore\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "google_api_key": {"load_from_db": false, "required": false, "placeholder": "", "show": true, "name": "google_api_key", "value": null, "display_name": "Google API Key", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The Google API Key to use for the Google Generative AI.", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}, "input_value": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "input_value", "value": "", "display_name": "Input", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageInput"}, "max_output_tokens": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "max_output_tokens", "value": 100000, "display_name": "Max Output Tokens", "advanced": false, "dynamic": false, "info": "The maximum number of tokens to generate.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "model": {"trace_as_metadata": true, "options": ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.0-pro", "gemini-1.0-pro-vision"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "model", "value": "gemini-1.5-flash", "display_name": "Model", "advanced": false, "dynamic": false, "info": "The name of the model to use.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "n": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "n", "value": "", "display_name": "N", "advanced": true, "dynamic": false, "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "stream": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "stream", "value": false, "display_name": "Stream", "advanced": true, "dynamic": false, "info": "Stream the response from the model. Streaming works only in Chat.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "system_message": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "system_message", "value": "", "display_name": "System Message", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "System message to pass to the model.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "temperature": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "temperature", "value": 0.1, "display_name": "Temperature", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "float", "_input_type": "FloatInput"}, "top_k": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "top_k", "value": "", "display_name": "Top K", "advanced": true, "dynamic": false, "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "top_p": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "top_p", "value": "", "display_name": "Top P", "advanced": true, "dynamic": false, "info": "The maximum cumulative probability of tokens to consider when sampling.", "title_case": false, "type": "float", "_input_type": "FloatInput"}}, "description": "Generate text using Google Generative AI.", "icon": "GoogleGenerativeAI", "base_classes": ["LanguageModel", "Message"], "display_name": "Google Generative AI", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "text_output", "display_name": "Text", "method": "text_response", "value": "__UNDEFINED__", "cache": true}, {"types": ["LanguageModel"], "selected": "LanguageModel", "name": "model_output", "display_name": "Language Model", "method": "build_model", "value": "__UNDEFINED__", "cache": true}], "field_order": ["input_value", "system_message", "stream", "max_output_tokens", "model", "google_api_key", "top_p", "temperature", "n", "top_k"], "beta": false, "edited": false, "lf_version": "1.0.16.post6"}, "id": "GoogleGenerativeAIModel-Se45g"}, "selected": false, "width": 384, "height": 691, "dragging": false, "positionAbsolute": {"x": 1218.5478040783785, "y": 112.3811252782433}}, {"id": "URL-c8dtP", "type": "genericNode", "position": {"x": -441.38642053557294, "y": 62.9578632591037}, "data": {"type": "URL", "node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "import re\n\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass URLComponent(Component):\n    display_name = \"URL\"\n    description = \"Fetch content from one or more URLs.\"\n    icon = \"layout-template\"\n    name = \"URL\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs, by clicking the '+' button.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n    ]\n\n    def ensure_url(self, string: str) -> str:\n        \"\"\"\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\n        Raises an error if the string is not a valid URL.\n\n        Parameters:\n            string (str): The string to be checked and possibly modified.\n\n        Returns:\n            str: The modified string that is ensured to be a URL.\n\n        Raises:\n            ValueError: If the string is not a valid URL.\n        \"\"\"\n        if not string.startswith((\"http://\", \"https://\")):\n            string = \"http://\" + string\n\n        # Basic URL validation regex\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\"  # optional protocol\n            r\"(www\\.)?\"  # optional www\n            r\"([a-zA-Z0-9.-]+)\"  # domain\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\n            r\"(:\\d+)?\"  # optional port\n            r\"(\\/[^\\s]*)?$\",  # optional path\n            re.IGNORECASE,\n        )\n\n        if not url_regex.match(string):\n            raise ValueError(f\"Invalid URL: {string}\")\n\n        return string\n\n    def fetch_content(self) -> list[Data]:\n        urls = [self.ensure_url(url.strip()) for url in self.urls if url.strip()]\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\n        docs = loader.load()\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\n        self.status = data\n        return data\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "urls": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": true, "required": false, "placeholder": "", "show": true, "name": "urls", "value": ["https://myawsbucket-stream.s3.eu-north-1.amazonaws.com/data_new_utf8.csv"], "display_name": "URLs", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Enter one or more URLs, by clicking the '+' button.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Fetch content from one or more URLs.", "icon": "layout-template", "base_classes": ["Data"], "display_name": "URL", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Data"], "selected": "Data", "name": "data", "display_name": "Data", "method": "fetch_content", "value": "__UNDEFINED__", "cache": true}], "field_order": ["urls"], "beta": false, "edited": false, "lf_version": "1.0.18"}, "id": "URL-c8dtP"}, "selected": false, "width": 384, "height": 302, "dragging": false, "positionAbsolute": {"x": -441.38642053557294, "y": 62.9578632591037}}], "edges": [{"className": "", "data": {"sourceHandle": {"dataType": "ChatInput", "id": "ChatInput-DSs0U", "name": "message", "output_types": ["Message"]}, "targetHandle": {"fieldName": "Question", "id": "Prompt-bSbBG", "inputTypes": ["Message", "Text"], "type": "str"}}, "id": "reactflow__edge-ChatInput-DSs0U{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-DSs0U\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-Prompt-bSbBG{\u0153fieldName\u0153:\u0153Question\u0153,\u0153id\u0153:\u0153Prompt-bSbBG\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153,\u0153Text\u0153],\u0153type\u0153:\u0153str\u0153}", "source": "ChatInput-DSs0U", "sourceHandle": "{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-DSs0U\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "Prompt-bSbBG", "targetHandle": "{\u0153fieldName\u0153:\u0153Question\u0153,\u0153id\u0153:\u0153Prompt-bSbBG\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153,\u0153Text\u0153],\u0153type\u0153:\u0153str\u0153}"}, {"className": "", "data": {"sourceHandle": {"dataType": "ParseData", "id": "ParseData-Opo2C", "name": "text", "output_types": ["Message"]}, "targetHandle": {"fieldName": "Document", "id": "Prompt-bSbBG", "inputTypes": ["Message", "Text"], "type": "str"}}, "id": "reactflow__edge-ParseData-Opo2C{\u0153dataType\u0153:\u0153ParseData\u0153,\u0153id\u0153:\u0153ParseData-Opo2C\u0153,\u0153name\u0153:\u0153text\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-Prompt-bSbBG{\u0153fieldName\u0153:\u0153Document\u0153,\u0153id\u0153:\u0153Prompt-bSbBG\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153,\u0153Text\u0153],\u0153type\u0153:\u0153str\u0153}", "source": "ParseData-Opo2C", "sourceHandle": "{\u0153dataType\u0153:\u0153ParseData\u0153,\u0153id\u0153:\u0153ParseData-Opo2C\u0153,\u0153name\u0153:\u0153text\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "Prompt-bSbBG", "targetHandle": "{\u0153fieldName\u0153:\u0153Document\u0153,\u0153id\u0153:\u0153Prompt-bSbBG\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153,\u0153Text\u0153],\u0153type\u0153:\u0153str\u0153}"}, {"source": "Prompt-bSbBG", "sourceHandle": "{\u0153dataType\u0153:\u0153Prompt\u0153,\u0153id\u0153:\u0153Prompt-bSbBG\u0153,\u0153name\u0153:\u0153prompt\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "GoogleGenerativeAIModel-Se45g", "targetHandle": "{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153GoogleGenerativeAIModel-Se45g\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "input_value", "id": "GoogleGenerativeAIModel-Se45g", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "Prompt", "id": "Prompt-bSbBG", "name": "prompt", "output_types": ["Message"]}}, "id": "reactflow__edge-Prompt-bSbBG{\u0153dataType\u0153:\u0153Prompt\u0153,\u0153id\u0153:\u0153Prompt-bSbBG\u0153,\u0153name\u0153:\u0153prompt\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-GoogleGenerativeAIModel-Se45g{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153GoogleGenerativeAIModel-Se45g\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "className": ""}, {"source": "GoogleGenerativeAIModel-Se45g", "sourceHandle": "{\u0153dataType\u0153:\u0153GoogleGenerativeAIModel\u0153,\u0153id\u0153:\u0153GoogleGenerativeAIModel-Se45g\u0153,\u0153name\u0153:\u0153text_output\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "ChatOutput-qVzbh", "targetHandle": "{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ChatOutput-qVzbh\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "input_value", "id": "ChatOutput-qVzbh", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "GoogleGenerativeAIModel", "id": "GoogleGenerativeAIModel-Se45g", "name": "text_output", "output_types": ["Message"]}}, "id": "reactflow__edge-GoogleGenerativeAIModel-Se45g{\u0153dataType\u0153:\u0153GoogleGenerativeAIModel\u0153,\u0153id\u0153:\u0153GoogleGenerativeAIModel-Se45g\u0153,\u0153name\u0153:\u0153text_output\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-ChatOutput-qVzbh{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ChatOutput-qVzbh\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "className": ""}, {"source": "URL-c8dtP", "sourceHandle": "{\u0153dataType\u0153:\u0153URL\u0153,\u0153id\u0153:\u0153URL-c8dtP\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}", "target": "ParseData-Opo2C", "targetHandle": "{\u0153fieldName\u0153:\u0153data\u0153,\u0153id\u0153:\u0153ParseData-Opo2C\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "data", "id": "ParseData-Opo2C", "inputTypes": ["Data"], "type": "other"}, "sourceHandle": {"dataType": "URL", "id": "URL-c8dtP", "name": "data", "output_types": ["Data"]}}, "id": "reactflow__edge-URL-c8dtP{\u0153dataType\u0153:\u0153URL\u0153,\u0153id\u0153:\u0153URL-c8dtP\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}-ParseData-Opo2C{\u0153fieldName\u0153:\u0153data\u0153,\u0153id\u0153:\u0153ParseData-Opo2C\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "selected": false, "className": ""}], "viewport": {"x": 296.69501750802556, "y": 253.45167643859475, "zoom": 0.5776519913579988}}, "user_id": "61495550-a241-4143-8c9a-bf8ba32c1841", "folder_id": "71c91345-be13-44e7-b1b1-12476a0979b6"}